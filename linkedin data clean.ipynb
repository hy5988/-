{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab001b30-ba04-4378-9256-3e0d6153fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 数据路径\n",
    "input_path = r\"C:\\Users\\15959\\linkedin\\archive\\linkdin_Job_data.csv\"\n",
    "output_path = r\"C:\\Users\\15959\\linkedin\\cleaned_linkedin_job_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5207716-977b-4395-83b2-24a8ac05150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Inspecting 'no_of_application' column for invalid data...\n",
      "Invalid data found:\n",
      "['minutes' 'hours' 'days' 'minute' 'day' 'hour' 'seconds']\n",
      "Cleaning 'linkedin_followers' column...\n",
      "Cleaning 'job_details' column...\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "print(\"Loading data...\")\n",
    "data = pd.read_csv(input_path)\n",
    "\n",
    "# 删除完全为空的列\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# 处理缺失值\n",
    "if 'job' in data.columns:\n",
    "    data['job'] = data['job'].fillna(\"Unknown Job\")\n",
    "\n",
    "if 'location' in data.columns:\n",
    "    data['location'] = data['location'].fillna(\"Unknown Location\")\n",
    "\n",
    "if 'company_name' in data.columns:\n",
    "    data['company_name'] = data['company_name'].fillna(\"Unknown Company\")\n",
    "\n",
    "if 'work_type' in data.columns:\n",
    "    data['work_type'] = data['work_type'].fillna(\"Unknown Work Type\")\n",
    "\n",
    "if 'full_time_remote' in data.columns:\n",
    "    data['full_time_remote'] = data['full_time_remote'].fillna(\"Unknown\")\n",
    "\n",
    "# 处理 'no_of_application' 列\n",
    "if 'no_of_application' in data.columns:\n",
    "    print(\"Inspecting 'no_of_application' column for invalid data...\")\n",
    "\n",
    "    # 确保列是字符串类型并填充 NaN 值\n",
    "    data['no_of_application'] = data['no_of_application'].fillna(\"0\").astype(str)\n",
    "\n",
    "    # 打印无效数据（非数字内容）\n",
    "    invalid_data = data[~data['no_of_application'].str.replace(\",\", \"\").str.isdigit()]\n",
    "    print(\"Invalid data found:\")\n",
    "    print(invalid_data['no_of_application'].unique())\n",
    "\n",
    "    # 清理无效数据：将非数值数据替换为 \"0\"\n",
    "    data['no_of_application'] = data['no_of_application'].str.replace(\",\", \"\")  # 移除逗号\n",
    "    data['no_of_application'] = data['no_of_application'].apply(lambda x: x if x.isdigit() else \"0\")\n",
    "    data['no_of_application'] = data['no_of_application'].astype(int)\n",
    "\n",
    "# 处理 'linkedin_followers' 列\n",
    "if 'linkedin_followers' in data.columns:\n",
    "    print(\"Cleaning 'linkedin_followers' column...\")\n",
    "    \n",
    "    # 移除非数值部分（如 'followers'）\n",
    "    data['linkedin_followers'] = data['linkedin_followers'].str.replace(\"followers\", \"\").str.strip()\n",
    "    data['linkedin_followers'] = data['linkedin_followers'].str.replace(\",\", \"\")  # 移除逗号\n",
    "    data['linkedin_followers'] = data['linkedin_followers'].fillna(\"0\")  # 填充缺失值\n",
    "    data['linkedin_followers'] = data['linkedin_followers'].apply(lambda x: x if x.isdigit() else \"0\")\n",
    "    data['linkedin_followers'] = data['linkedin_followers'].astype(int)\n",
    "\n",
    "# 处理 'posted_day_ago' 列\n",
    "if 'posted_day_ago' in data.columns:\n",
    "    data['posted_day_ago'] = data['posted_day_ago'].fillna(\"0 days\")\n",
    "    data['posted_day_ago'] = data['posted_day_ago'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# 处理 'job_details' 列，计算其长度\n",
    "if 'job_details' in data.columns:\n",
    "    print(\"Cleaning 'job_details' column...\")\n",
    "    \n",
    "    # 确保所有值为字符串类型，并填充 NaN 为默认值\n",
    "    data['job_details'] = data['job_details'].fillna(\"\").astype(str)\n",
    "    \n",
    "    # 计算每行的字符串长度\n",
    "    data['job_details_length'] = data['job_details'].apply(len)\n",
    "\n",
    "# 生成新特征\n",
    "if 'full_time_remote' in data.columns:\n",
    "    data['is_remote'] = data['full_time_remote'].apply(lambda x: 1 if 'remote' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f90ae65-47f8-4ff1-894a-4119d55c6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充剩余缺失值\n",
    "if 'no_of_employ' in data.columns:\n",
    "    data['no_of_employ'] = data['no_of_employ'].fillna(\"Unknown\")\n",
    "\n",
    "if 'alumni' in data.columns:\n",
    "    data['alumni'] = data['alumni'].fillna(\"Not provided\")\n",
    "\n",
    "if 'Hiring_person' in data.columns:\n",
    "    data['Hiring_person'] = data['Hiring_person'].fillna(\"Unknown\")\n",
    "\n",
    "# 改进 is_remote 特征提取\n",
    "if 'full_time_remote' in data.columns:\n",
    "    data['is_remote'] = data['full_time_remote'].apply(lambda x: 1 if 'remote' in x.lower() else 0)\n",
    "\n",
    "if 'hiring_person_link' in data.columns:\n",
    "    data['hiring_person_link'] = data['hiring_person_link'].fillna(\"No link available\")\n",
    "\n",
    "if 'full_time_remote' in data.columns:\n",
    "    data['is_remote'] = data['full_time_remote'].apply(lambda x: 1 if 'remote' in x.lower() or 'wfh' in x.lower() else 0)\n",
    "\n",
    "if 'full_time_remote' in data.columns:\n",
    "    data['is_remote'] = data['full_time_remote'].apply(\n",
    "        lambda x: 1 if 'remote' in x.lower() or 'wfh' in x.lower() else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "822d8435-af92-4c4a-8132-f66046df9943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       job_ID                                                job  \\\n",
      "0  3471657636  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
      "1  3471669068  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
      "2  3474349934                                 Data Analyst - WFH   \n",
      "3  3472816027                                       Data Analyst   \n",
      "4  3473311511                                       Data Analyst   \n",
      "\n",
      "                         location              company_name work_type  \\\n",
      "0             Delhi, Delhi, India                 Crossover    Remote   \n",
      "1         New Delhi, Delhi, India                 Crossover    Remote   \n",
      "2          Greater Bengaluru Area                    Uplers    Remote   \n",
      "3        Gurugram, Haryana, India             PVAR SERVICES   On-site   \n",
      "4  Mohali district, Punjab, India  Timeline Freight Brokers   On-site   \n",
      "\n",
      "               full_time_remote  \\\n",
      "0         Full-time · Associate   \n",
      "1         Full-time · Associate   \n",
      "2  Full-time · Mid-Senior level   \n",
      "3                     Full-time   \n",
      "4                     Full-time   \n",
      "\n",
      "                                        no_of_employ  no_of_application  \\\n",
      "0  1,001-5,000 employees · IT Services and IT Con...                200   \n",
      "1  1,001-5,000 employees · IT Services and IT Con...                184   \n",
      "2  1,001-5,000 employees · IT Services and IT Con...                200   \n",
      "3                                     1-10 employees                200   \n",
      "4                                     1-10 employees                  8   \n",
      "\n",
      "   posted_day_ago             alumni           Hiring_person  \\\n",
      "0               8  12 company alumni                 Unknown   \n",
      "1               8  12 company alumni                 Unknown   \n",
      "2               9   3 company alumni            Shahid Ahmad   \n",
      "3               7       Not provided           Vartika Singh   \n",
      "4              26   1 company alumni  Manisha (Gisele Smith)   \n",
      "\n",
      "   linkedin_followers                                 hiring_person_link  \\\n",
      "0             5395547                                  No link available   \n",
      "1             5395547                                  No link available   \n",
      "2                   0  https://www.linkedin.com/in/shahid-ahmad-a2613...   \n",
      "3                2094         https://www.linkedin.com/in/vartika-singh-   \n",
      "4                   0     https://www.linkedin.com/in/manisharathore0029   \n",
      "\n",
      "                                         job_details  job_details_length  \\\n",
      "0  About the job Crossover is the world's #1 sour...                3736   \n",
      "1  About the job Crossover is the world's #1 sour...                3739   \n",
      "2  About the job Profile: ML EngineersExperience:...                4572   \n",
      "3  About the job Designation: Data AnalystLocatio...                1472   \n",
      "4  About the job The ideal candidate will use the...                1101   \n",
      "\n",
      "   is_remote  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "\n",
      "Missing values in each column:\n",
      "job_ID                0\n",
      "job                   0\n",
      "location              0\n",
      "company_name          0\n",
      "work_type             0\n",
      "full_time_remote      0\n",
      "no_of_employ          0\n",
      "no_of_application     0\n",
      "posted_day_ago        0\n",
      "alumni                0\n",
      "Hiring_person         0\n",
      "linkedin_followers    0\n",
      "hiring_person_link    0\n",
      "job_details           0\n",
      "job_details_length    0\n",
      "is_remote             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 查看数据的前几行，确认清洗结果\n",
    "print(data.head())\n",
    "\n",
    "# 检查是否还有缺失值\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b2c1cd-1dd3-4e05-9332-0d75d7768940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: C:\\Users\\15959\\linkedin\\cleaned_linkedin_job_data.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存清洗后的数据\n",
    "output_path = r\"C:\\Users\\15959\\linkedin\\cleaned_linkedin_job_data.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b5984-cb07-4c88-bf7c-51adecd0dcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
